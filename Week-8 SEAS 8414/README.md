# Miniâ€‘SOAR â†’ Cognitive SOAR (Prediction âœ Attribution)

This project evolves a Miniâ€‘SOAR URL classifier into a Cognitive SOAR that adds threat attribution after detection.

- Step 1 â€” Prediction (Supervised): Classify a URL as MALICIOUS or BENIGN using a PyCaret classification model.
- Step 2 â€” Attribution (Unsupervised): If MALICIOUS, infer a likely actor profile with a clustering model (**Kâ€‘Means, k=3**) and map the cluster to:
  - Stateâ€‘Sponsored
  - Organized Cybercrime
  - Hacktivist

This extra context helps analysts route incidents, pick the right playbooks, and communicate impact quickly.

---

## Key Features
- Dualâ€‘model pipeline (two separate PyCaret `setup()` runs)
- Stable clusterâ†’actor mapping persisted to `models/cluster_mapping.json`
- Streamlit UI with tabs: single analysis, threat attribution (shown only when malicious), batch CSV
- Dockerized for easy run, plus GitHub Actions linting

---

## Architecture (Dualâ€‘Model)
```
[User Features] â†’ [Classifier] â”€â”€ MALICIOUS? â”€â”€â–º [Clusterer (K=3)] â”€â–º [Actor Mapping] â”€â–º â€œState | Crime | Hacktivistâ€
                         â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ BENIGN â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- Classifier (supervised): Trained on synthetic labels `BENIGN` vs `MALICIOUS`.
- Clusterer (unsupervised): Trained on features only; its numeric cluster IDs are mapped to actor labels via majority vote on the training set and saved to JSON.

Artifacts (after training):
- `models/phishing_url_detector.pkl`
- `models/threat_actor_profiler.pkl`
- `models/cluster_mapping.json`

---

## Tech Stack
- Python, PyCaret, scikitâ€‘learn
- Streamlit** (UI)
- Docker / Compose** (containerized dev)
- Optional: OpenAI / Gemini for prescriptive text (via `genai_prescriptions.py`)

---

## Repository Layout
```
mini-soar/
â”œâ”€â”€ .github/workflows/lint.yml
â”œâ”€â”€ README.md
â”œâ”€â”€ INSTALL.md
â”œâ”€â”€ TESTING.md
â”œâ”€â”€ Makefile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ train_model.py
â”œâ”€â”€ genai_prescriptions.py
â””â”€â”€ app.py
```

---

##Usage

### Local
```bash
pip install -r requirements.txt
python train_model.py
streamlit run app.py
# open http://localhost:8501
```

### Docker
```bash
docker compose up --build
# open http://localhost:8501
```

---

## ğŸ§ª Models & Data
Training writes artifacts to `models/`:
- `phishing_url_detector.pkl` (classifier)
- `threat_actor_profiler.pkl` (clusterer)
- `cluster_mapping.json` (cluster ID â†’ actor label)
- `synthetic_urls.csv` (generated dataset for inspection)

---

## CI / Automation
A GitHub Actions workflow runs flake8 lint on every push/PR: `.github/workflows/lint.yml`.

---

##  Notes
- Attribution is heuristic context, not proof. Use it to guide triage and playbooks.
- Clustering runs only when the verdict is MALICIOUS.